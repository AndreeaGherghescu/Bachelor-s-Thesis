{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-23T18:24:58.354047321Z",
     "start_time": "2023-05-23T18:24:56.533467346Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import re\n",
    "import joblib\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "pop_directory = \"Data/pop\"\n",
    "rock_directory = \"Data/rock\"\n",
    "country_directory = \"Data/country\"\n",
    "rock_pop_directory = \"Data/rock_pop\"\n",
    "\n",
    "save_pop = \"assembled_pop\"\n",
    "save_rock = \"assembled_rock\"\n",
    "save_country = \"assembled_country\"\n",
    "save_rock_pop = \"assembled_rock_pop\"\n",
    "\n",
    "filename_gen = \"SD3_v3/GeneratorSD3_v3.joblib\"\n",
    "generator = joblib.load(filename_gen)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T18:24:58.390671552Z",
     "start_time": "2023-05-23T18:24:58.357256934Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# class MyImageFolder(torch.utils.data.Dataset):\n",
    "#     def __init__(self, directory:str, transform=None):\n",
    "#\n",
    "#         self.paths = list(pathlib.Path(directory).glob('*/*.jpg'))\n",
    "#\n",
    "#         self.transform = transform\n",
    "#\n",
    "#     def __len__(self):\n",
    "#         return len(self.paths)\n",
    "#\n",
    "#     def __getitem__(self, index):\n",
    "#         img = self.load_image(index)\n",
    "#         class_name = self.paths[index].parent.name\n",
    "#         class_index = self.class_to_index[class_name]\n",
    "#\n",
    "#         if self.transform:\n",
    "#             return self.transform(img), class_index\n",
    "#         else:\n",
    "#             return img, class_index\n",
    "#\n",
    "#     def load_image(self, index):\n",
    "#         image_path = self.paths[index]\n",
    "#         return Image.open(image_path)\n",
    "#\n",
    "# transform = torchvision.transforms.Compose([\n",
    "#             torchvision.transforms.ToTensor(),  # imaginile sunt normalizate intre [0, 1]\n",
    "#         ])\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T18:24:58.394939973Z",
     "start_time": "2023-05-23T18:24:58.391734242Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In assemble\n",
      "In assemble\n"
     ]
    }
   ],
   "source": [
    "def load_image(paths, index):\n",
    "    image_path = paths[index]\n",
    "    # print(image_path)\n",
    "    return Image.open(image_path)\n",
    "\n",
    "def assemble(about, paths, save, genre):\n",
    "    print(\"In assemble\")\n",
    "    for ind, i in enumerate(about):\n",
    "        # assemble the i-th spectrogram\n",
    "        total_width = i[0]\n",
    "        s_per_line = total_width // 32\n",
    "        extra = 0\n",
    "        if total_width % 32 != 0:  # daca latimea nu se imparte la 32 inseamna ca mai avem o bucata incompleta la final\n",
    "            extra = 1\n",
    "\n",
    "        final_spect = Image.new('L', (total_width, 128))\n",
    "        counter = i[1][0]\n",
    "        for j in range(4):\n",
    "            # j numara liniile\n",
    "            for k in range(s_per_line):\n",
    "                # k numara coloanele\n",
    "                # incarcam cate o bucata si o punem pe pozitia ei\n",
    "                spect = load_image(paths, counter)\n",
    "                final_spect.paste(spect, (k * 32, j * 32))\n",
    "                counter += 1\n",
    "            if extra:\n",
    "                spect = load_image(paths, counter)\n",
    "                counter += 1\n",
    "                remaining = total_width % 32\n",
    "                spect_np = np.array(spect)\n",
    "                last_columns = spect_np[:, -remaining:]\n",
    "                spect = Image.fromarray(last_columns)\n",
    "                final_spect.paste(spect, (total_width // 32, j * 32))\n",
    "\n",
    "        final_spect.save(f\"Data/{save}/{genre}_spec{ind}.jpg\")\n",
    "        if counter != i[1][1] : print(counter, i[1][1])\n",
    "\n",
    "\n",
    "def transform_spects(paths, genre):\n",
    "    print(\"In transform\")\n",
    "    for ind in tqdm(range(len(paths))):\n",
    "        image = load_image(paths, ind)\n",
    "        if ind == 0:\n",
    "            fig, axs = plt.subplots(1)\n",
    "            axs.imshow(image)\n",
    "            plt.show()\n",
    "\n",
    "        make_tensor = torchvision.transforms.ToTensor()\n",
    "        image = make_tensor(image)\n",
    "\n",
    "        if ind == 0:\n",
    "            image = torch.transpose(image, 0, 2)\n",
    "            fig, axs = plt.subplots(1)\n",
    "            axs.imshow(image)\n",
    "            plt.show()\n",
    "            image = torch.transpose(image, 0, 2)\n",
    "\n",
    "        image = torch.unsqueeze(image, 0)\n",
    "        image = generator(image)\n",
    "        # daca nu merge fac cu slice\n",
    "\n",
    "        image = torch.squeeze(image, 0)\n",
    "        if ind == 0:\n",
    "            image = torch.transpose(image, 0, 2)\n",
    "            fig, axs = plt.subplots(1)\n",
    "            axs.imshow(image.detach())\n",
    "            plt.show()\n",
    "            image = torch.transpose(image, 0, 2)\n",
    "\n",
    "        # image_arr = np.array(image)\n",
    "        # image_tensor = torch.from_numpy(image_arr)\n",
    "        # image_tensor = image_tensor.to(torch.float32)\n",
    "        # image_tensor = torch.unsqueeze(image_tensor, 0)\n",
    "        # image_tensor = torch.unsqueeze(image_tensor, 0)\n",
    "        # new_image = generator(image_tensor)\n",
    "        # new_image = torch.squeeze(new_image)\n",
    "\n",
    "        #image = torch.transpose(image, 0, 2)\n",
    "        image = torch.squeeze(image, 0)\n",
    "\n",
    "        new_np = image.detach().numpy().astype(np.float32)\n",
    "        new_np = (new_np * 255).astype(np.uint8)\n",
    "        if ind == 0:\n",
    "            fig, axs = plt.subplots(1)\n",
    "            axs.imshow(new_np)\n",
    "            plt.show()\n",
    "\n",
    "        im = Image.fromarray(new_np)\n",
    "        if im.mode != 'L':\n",
    "            im = im.convert('L')\n",
    "        im.save(f\"Data/{genre}/{genre}_spec{ind}.jpg\")\n",
    "\n",
    "\n",
    "about_pop = np.load('pop_items.npy', allow_pickle=True)\n",
    "#about_rock = np.load('rock_items.npy', allow_pickle=True)\n",
    "about_country = np.load('country_items.npy', allow_pickle=True)\n",
    "\n",
    "pop_paths = sorted(pathlib.Path(pop_directory).glob('*.jpg'), key=lambda p: int(re.search(r'\\d+', p.stem).group()))\n",
    "#rock_paths = sorted(pathlib.Path(rock_directory).glob('*.jpg'), key=lambda p: int(re.search(r'\\d+', p.stem).group()))\n",
    "country_paths = sorted(pathlib.Path(country_directory).glob('*.jpg'), key=lambda p: int(re.search(r'\\d+', p.stem).group()))\n",
    "\n",
    "#transform_spects(rock_paths, 'rock_pop')\n",
    "\n",
    "#rock_pop_paths = sorted(pathlib.Path(rock_pop_directory).glob('*.jpg'), key=lambda p: int(re.search(r'\\d+', p.stem).group()))\n",
    "\n",
    "assemble(about_pop, pop_paths, save_pop, 'pop')\n",
    "#assemble(about_rock, rock_paths, save_rock, 'rock')\n",
    "assemble(about_country, country_paths, save_country, 'country')\n",
    "#assemble(about_rock, rock_pop_paths, save_rock_pop, 'rock_pop')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T19:17:43.109990800Z",
     "start_time": "2023-05-23T19:17:40.534780788Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-23T18:27:01.181421797Z",
     "start_time": "2023-05-23T18:27:01.177820685Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
